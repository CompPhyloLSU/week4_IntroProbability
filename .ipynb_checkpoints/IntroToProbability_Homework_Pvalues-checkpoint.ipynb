{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4 Homework - P-values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You flip a coin 20 times and observe 5 heads. This seems low if the coin is fair, but just how improbable is it? One way to address this is to simulate a large number of 20 coin flips and see how many of these simulations result in 5 or fewer heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "12\n",
      "9\n",
      "6\n",
      "9\n",
      "12\n",
      "10\n",
      "6\n",
      "12\n",
      "8\n",
      "8\n",
      "9\n",
      "10\n",
      "7\n",
      "9\n",
      "10\n",
      "15\n",
      "7\n",
      "10\n",
      "9\n",
      "6\n",
      "10\n",
      "10\n",
      "11\n",
      "14\n",
      "12\n",
      "9\n",
      "14\n",
      "8\n",
      "10\n",
      "15\n",
      "14\n",
      "11\n",
      "10\n",
      "13\n",
      "8\n",
      "11\n",
      "11\n",
      "9\n",
      "7\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "5\n",
      "9\n",
      "8\n",
      "7\n",
      "12\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "sampleSpace = [\"heads\",\"tails\"]\n",
    "\n",
    "for (rep in 1:50){\n",
    "        headCounts = 0\n",
    "\n",
    "    numSamples = 20\n",
    "    for (s in 1:numSamples){\n",
    "        sample = sampleSpace[runifInt(1,1,sampleSpace.size())[1]]\n",
    "        if (sample == \"heads\"){\n",
    "            headCounts += 1\n",
    "        }\n",
    "    }\n",
    "    print(headCounts)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you'll need to compare your observation (5 heads) to your simulations. Using a `for` loop, go through your results and count the number of simulated values that are less than or equal to your observed value. Convert your count into a frequency by dividing by the total number of simulations you ran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "   FALSE\n",
      "0.02\n"
     ]
    }
   ],
   "source": [
    "for (i in 1:50){\n",
    "    lowheadCount = 0\n",
    "        if (sample == \"heads\"){\n",
    "            headCounts <= 5\n",
    "            lowheadCount += 1\n",
    "        }\n",
    "    }\n",
    "    print(lowheadCount/50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How probable was the observed number of heads? Do you believe your coin to be fair?\n",
    "\n",
    "Another way to get this probability is not using simulations. For standard distributions like the binomial, there are built-in probability mass functions with known probabilities for different outcomes. These are similar to the functions used to draw values from a distribution, but in this case they start with a `d`. For the binomial, this function takes 4 arguments:\n",
    "\n",
    "1. number of successes (heads)\n",
    "2. probability of success (0.5 for a fair coin)\n",
    "3. number of trials (coin flips)\n",
    "4. a boolean to see if you want the log of the probability (use FALSE here)\n",
    "\n",
    "To get the total probability of 0, 1, 2, 3, 4, and 5, you'll need to call this function once for each number of successes and add the probabilities together. How does this compare to the value you estimated above using simulations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02069473\n"
     ]
    }
   ],
   "source": [
    "heads0 = dbinomial (0, 0.5, 20, FALSE)\n",
    "heads1 = dbinomial (1, 0.5, 20, FALSE)\n",
    "heads2 = dbinomial (2, 0.5, 20, FALSE)\n",
    "heads3 = dbinomial (3, 0.5, 20, FALSE)\n",
    "heads4 = dbinomial (4, 0.5, 20, FALSE)\n",
    "heads5 = dbinomial (5, 0.5, 20, FALSE)\n",
    "\n",
    "totalProb = heads0 + heads1 + heads2 + heads3 + heads4 + heads5\n",
    "\n",
    "print (totalProb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probabilities you've just calculated or estimated above are the lower one-tailed p-values associated with observing 5 heads if your null hypothesis is a fair coin. What is the standard threshold for p-values in order to reject the null hypothesis (often called alpha)? Using this value, would you reject the hypothesis of a fair coin?\n",
    "\n",
    "Null hypothesis is rejected because p-value is under standard threshold 0.05.\n",
    "\n",
    "What's a two-tailed p-value? How would you calculate that in this case? Using a two-tailed value, would you still reject the fair coin model?\n",
    "\n",
    "Tests for p-value in either direction with standard threshold 0.025, still rejecting null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RevBayes",
   "language": "bash",
   "name": "revbayes_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "r"
   },
   "file_extension": ".Rev",
   "help_links": [
    {
     "text": "RevBayes",
     "url": "https://revbayes.org"
    },
    {
     "text": "RevBayes Kernel",
     "url": "https://github.com/sdwfrost/revbayes_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-rsrc",
   "name": "RevBayes",
   "pygments_lexer": "R"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
